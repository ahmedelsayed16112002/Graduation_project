{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2BdrhubFEW8"
      },
      "source": [
        "## Install Necessary Libraries\n",
        "This cell installs the required Python libraries for data processing, machine learning, API creation, and tunneling to make the API publicly accessible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQKNslXB6k5O",
        "outputId": "c0fc2f82-76ec-43d3-a414-b26803a18a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.11)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.10.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.27.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn fastapi pydantic joblib uvicorn nest-asyncio pyngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wz3vZCSFMhQ"
      },
      "source": [
        "## Import Libraries\n",
        "This cell imports all necessary libraries for data manipulation, model training, evaluation, and API deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bNCKGSp3FJbf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import joblib\n",
        "from google.colab import files\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from pyngrok import conf, ngrok\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from threading import Thread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qo4B85RFQMj"
      },
      "source": [
        "## Upload and Load Dataset\n",
        "This cell prompts the user to upload a dataset (e.g., `student_data.csv`) and loads it into a pandas DataFrame for further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "9uoPWMWwFO0b",
        "outputId": "5a3a2ee0-6b5b-4440-d76d-08d85e70d2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your dataset (e.g., student_data.csv):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-95e6fff2-4b1a-4f8d-939b-643064c2b614\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-95e6fff2-4b1a-4f8d-939b-643064c2b614\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.csv to data (1).csv\n"
          ]
        }
      ],
      "source": [
        "print(\"Please upload your dataset (e.g., student_data.csv):\")\n",
        "uploaded = files.upload()\n",
        "data = pd.read_csv(list(uploaded.keys())[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfs6nX_bFh8r"
      },
      "source": [
        "## Define Target Variables\n",
        "This cell defines two target variables:\n",
        "- `Needs_Support`: 1 if `Exam_Score` is below 60, else 0.\n",
        "- `Engagement_Level`: A categorical feature derived from `Attendance`, `Extracurricular_Activities`, and `Motivation_Level`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gZIJR8v0FRuO"
      },
      "outputs": [],
      "source": [
        "threshold = 60  # Adjustable threshold for support\n",
        "data['Needs_Support'] = (data['Exam_Score'] < threshold).astype(int)\n",
        "data = data.drop('Exam_Score', axis=1)\n",
        "\n",
        "# Define Engagement_Level based on a sum of mapped values\n",
        "data['Engagement_Level'] = pd.cut(\n",
        "    data[['Attendance', 'Extracurricular_Activities', 'Motivation_Level']].apply(\n",
        "        lambda x: x.map({'Low': 1, 'Medium': 2, 'High': 3}).sum(), axis=1),\n",
        "    bins=3, labels=['Low', 'Medium', 'High']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XfOIpJFFlP1"
      },
      "source": [
        "## Preprocess Data\n",
        "This cell handles missing values in categorical columns using the most frequent value and applies one-hot encoding to categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b9gQYvQmFjY5"
      },
      "outputs": [],
      "source": [
        "categorical_cols = data.select_dtypes(include=['object']).columns\n",
        "numerical_cols = data.select_dtypes(exclude=['object']).columns\n",
        "\n",
        "# Impute missing values in categorical columns\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data[categorical_cols] = imputer.fit_transform(data[categorical_cols])\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "encoded_cols = pd.DataFrame(encoder.fit_transform(data[categorical_cols]))\n",
        "encoded_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
        "data = pd.concat([data, encoded_cols], axis=1).drop(categorical_cols, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rewKpAiFouj"
      },
      "source": [
        "## Split Data for Models\n",
        "This cell splits the data into training and testing sets for the `Needs_Support` and `Engagement_Level` models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TWAs2uMcFm7r"
      },
      "outputs": [],
      "source": [
        "# Split for Needs_Support model\n",
        "X_support = data.drop(['Needs_Support', 'Engagement_Level'], axis=1)\n",
        "y_support = data['Needs_Support']\n",
        "X_support_train, X_support_test, y_support_train, y_support_test = train_test_split(X_support, y_support, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split for Engagement_Level model\n",
        "X_engage = data.drop(['Needs_Support', 'Engagement_Level'], axis=1)\n",
        "y_engage = data['Engagement_Level']\n",
        "X_engage_train, X_engage_test, y_engage_train, y_engage_test = train_test_split(X_engage, y_engage, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M0lINepFr6H"
      },
      "source": [
        "## Train and Evaluate Needs_Support Model\n",
        "This cell trains a RandomForestClassifier for `Needs_Support`, tunes hyperparameters with GridSearchCV, performs cross-validation, and evaluates performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yspRHPcwFqJk",
        "outputId": "5fb0feaf-9ecf-45dd-9bcf-3b7853e96e0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracy (Support Model): 0.99 (±0.00)\n",
            "Support Model - Accuracy: 0.99\n",
            "Support Model - Precision: 1.00\n",
            "Support Model - Recall: 0.09\n"
          ]
        }
      ],
      "source": [
        "clf_support = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "grid_search = GridSearchCV(clf_support, param_grid, cv=5, scoring='f1')\n",
        "grid_search.fit(X_support_train, y_support_train)\n",
        "clf_support = grid_search.best_estimator_\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores = cross_val_score(clf_support, X_support_train, y_support_train, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-Validation Accuracy (Support Model): {cv_scores.mean():.2f} (±{cv_scores.std():.2f})\")\n",
        "\n",
        "# Train and evaluate\n",
        "clf_support.fit(X_support_train, y_support_train)\n",
        "y_support_pred = clf_support.predict(X_support_test)\n",
        "print(f\"Support Model - Accuracy: {accuracy_score(y_support_test, y_support_pred):.2f}\")\n",
        "print(f\"Support Model - Precision: {precision_score(y_support_test, y_support_pred):.2f}\")\n",
        "print(f\"Support Model - Recall: {recall_score(y_support_test, y_support_pred):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zisT-QFOFuk0"
      },
      "source": [
        "## Train and Evaluate Engagement_Level Model\n",
        "This cell trains a RandomForestClassifier for `Engagement_Level` and evaluates its accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VVFFJp_FtxP",
        "outputId": "506459e1-ba03-435c-8eef-9a9d18245e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Engagement Model - Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "clf_engage = RandomForestClassifier(random_state=42)\n",
        "clf_engage.fit(X_engage_train, y_engage_train)\n",
        "y_engage_pred = clf_engage.predict(X_engage_test)\n",
        "print(f\"Engagement Model - Accuracy: {accuracy_score(y_engage_test, y_engage_pred):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2bWoy0tFz79"
      },
      "source": [
        "## Save Models and Encoder\n",
        "This cell saves the trained models and the one-hot encoder to disk for later use in the API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSGToz3vFyV9",
        "outputId": "51b2348e-e8db-45c1-f759-73cd1bdc7bb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['encoder.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "joblib.dump(clf_support, 'support_model.joblib')\n",
        "joblib.dump(clf_engage, 'engage_model.joblib')\n",
        "joblib.dump(encoder, 'encoder.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL2tMMb3F2q5"
      },
      "source": [
        "## Define FastAPI App\n",
        "This cell sets up a FastAPI application, loads the saved models and encoder, and defines a `/predict` endpoint to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tW0jfirfF1RM"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, HTTPException\n",
        "from contextlib import asynccontextmanager\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Define the lifespan handler\n",
        "@asynccontextmanager\n",
        "async def lifespan(app: FastAPI):\n",
        "    # Startup code: runs when the app starts\n",
        "    print(\"Starting up the FastAPI application...\")\n",
        "    print(\"Support model classes:\", model_support.classes_)  # Verify class order\n",
        "    yield  # This is where the app runs\n",
        "    # Shutdown code (optional): runs when the app stops\n",
        "    print(\"Shutting down the FastAPI application...\")\n",
        "\n",
        "# Initialize the app with the lifespan handler\n",
        "app = FastAPI(lifespan=lifespan)\n",
        "\n",
        "# Load models and encoder (assuming these are already saved)\n",
        "model_support = joblib.load('support_model.joblib')\n",
        "model_engage = joblib.load('engage_model.joblib')\n",
        "encoder = joblib.load('encoder.joblib')\n",
        "\n",
        "# Define the StudentData model (unchanged)\n",
        "class StudentData(BaseModel):\n",
        "    Hours_Studied: int\n",
        "    Attendance: int\n",
        "    Parental_Involvement: str\n",
        "    Access_to_Resources: str\n",
        "    Extracurricular_Activities: str\n",
        "    Sleep_Hours: int\n",
        "    Previous_Scores: int\n",
        "    Motivation_Level: str\n",
        "    Internet_Access: str\n",
        "    Tutoring_Sessions: int\n",
        "    Family_Income: str\n",
        "    Teacher_Quality: str\n",
        "    School_Type: str\n",
        "    Peer_Influence: str\n",
        "    Physical_Activity: int\n",
        "    Learning_Disabilities: str\n",
        "    Parental_Education_Level: str\n",
        "    Distance_from_Home: str\n",
        "    Gender: str\n",
        "\n",
        "# Define the /predict endpoint with updated output format\n",
        "@app.post(\"/predict\")\n",
        "async def predict(student: StudentData):\n",
        "    try:\n",
        "        # Convert input to DataFrame\n",
        "        input_data = pd.DataFrame([student.model_dump()])\n",
        "\n",
        "        # Preprocess categorical columns with the encoder\n",
        "        categorical_cols = [col for col in input_data.columns if input_data[col].dtype == 'object']\n",
        "        encoded_input = pd.DataFrame(encoder.transform(input_data[categorical_cols]))\n",
        "        encoded_input.columns = encoder.get_feature_names_out(categorical_cols)\n",
        "        input_data = pd.concat([input_data, encoded_input], axis=1).drop(categorical_cols, axis=1)\n",
        "\n",
        "        # Prediction for Needs_Support\n",
        "        input_support = input_data.reindex(columns=model_support.feature_names_in_, fill_value=0)\n",
        "        pred_support = model_support.predict(input_support)[0]\n",
        "        prob_support = model_support.predict_proba(input_support)[0]\n",
        "\n",
        "        # Prediction for Engagement_Level\n",
        "        input_engage = input_data.reindex(columns=model_engage.feature_names_in_, fill_value=0)\n",
        "        pred_engage = model_engage.predict(input_engage)[0]\n",
        "\n",
        "        # Convert Needs_Support to descriptive string\n",
        "        support_status = \"Needs support\" if pred_support == 1 else \"Does not need support\"\n",
        "\n",
        "        # Convert probabilities to a labeled dictionary\n",
        "        support_prob = {\n",
        "            \"Probability of not needing support\": float(prob_support[0]),  # Convert to float for JSON serialization\n",
        "            \"Probability of needing support\": float(prob_support[1])       # Convert to float for JSON serialization\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"Needs_Support\": support_status,\n",
        "            \"Support_Probability\": support_prob,\n",
        "            \"Engagement_Level\": pred_engage\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=str(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7suWajMaNra",
        "outputId": "d8f97825-b6a7-4532-8d2d-10091f71bad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-bf5019bad554>:1: DeprecationWarning: \n",
            "        on_event is deprecated, use lifespan event handlers instead.\n",
            "\n",
            "        Read more about it in the\n",
            "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
            "        \n",
            "  @app.on_event(\"startup\")\n"
          ]
        }
      ],
      "source": [
        "@app.on_event(\"startup\")\n",
        "async def startup_event():\n",
        "    print(\"Support model classes:\", model_support.classes_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29KttG-bF627"
      },
      "source": [
        "## Set Up Ngrok and Run Server\n",
        "This cell configures ngrok with your authentication token, starts the FastAPI server in a background thread, and provides a public URL for access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18zfyYyRF4tM",
        "outputId": "c70a343c-6a0b-42f8-ef0d-8512dc90ec7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected port 46207 for the server.\n",
            "Starting the server on port 46207...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [2354]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:46207 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting ngrok to port 46207...\n",
            "Starting up the FastAPI application...\n",
            "Support model classes: [0 1]\n",
            "Server is now accessible at https://2573-35-197-33-30.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "from threading import Thread\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Function to find an available port\n",
        "def get_free_port():\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.bind(('', 0))  # Bind to port 0 to let the OS assign a free port\n",
        "        return s.getsockname()[1]  # Return the assigned port\n",
        "\n",
        "# Get an available port\n",
        "port = get_free_port()\n",
        "print(f\"Selected port {port} for the server.\")\n",
        "\n",
        "# Define the server function\n",
        "def run_server():\n",
        "    print(f\"Starting the server on port {port}...\")\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=port)  # 'app' is your FastAPI app\n",
        "\n",
        "# Start the server in a thread\n",
        "thread = Thread(target=run_server)\n",
        "thread.start()\n",
        "\n",
        "# Set your Ngrok auth token\n",
        "ngrok.set_auth_token(\"2tvNB9xCZcTaCKe6VGJ8rCtzjwB_4p8NDQSywaMkQFStRPjHP\")\n",
        "\n",
        "# Connect ngrok to the selected port\n",
        "print(f\"Connecting ngrok to port {port}...\")\n",
        "ngrok_tunnel = ngrok.connect(port)\n",
        "print(f\"Server is now accessible at {ngrok_tunnel.public_url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBHHV7JOF-Es"
      },
      "source": [
        "## Test the API\n",
        "This cell demonstrates how to test the `/predict` endpoint using the `requests` library with sample student data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VGBK0ehF8tb",
        "outputId": "561df38f-28e9-465c-c918-63236f28fadb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     35.197.33.30:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
            "Prediction: {'Needs_Support': 'Does not need support', 'Support_Probability': {'Probability of not needing support': 0.9823287658646125, 'Probability of needing support': 0.017671234135387407}, 'Engagement_Level': 'Medium'}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# Example input data (adjust based on your dataset)\n",
        "student_input = {\n",
        "    \"Hours_Studied\": 5,\n",
        "    \"Attendance\": 90,\n",
        "    \"Parental_Involvement\": \"High\",\n",
        "    \"Access_to_Resources\": \"Yes\",\n",
        "    \"Extracurricular_Activities\": \"Yes\",\n",
        "    \"Sleep_Hours\": 7,\n",
        "    \"Previous_Scores\": 75,\n",
        "    \"Motivation_Level\": \"Medium\",\n",
        "    \"Internet_Access\": \"Yes\",\n",
        "    \"Tutoring_Sessions\": 2,\n",
        "    \"Family_Income\": \"Middle\",\n",
        "    \"Teacher_Quality\": \"Good\",\n",
        "    \"School_Type\": \"Public\",\n",
        "    \"Peer_Influence\": \"Positive\",\n",
        "    \"Physical_Activity\": 3,\n",
        "    \"Learning_Disabilities\": \"No\",\n",
        "    \"Parental_Education_Level\": \"College\",\n",
        "    \"Distance_from_Home\": \"Near\",\n",
        "    \"Gender\": \"Male\"\n",
        "}\n",
        "\n",
        "# Send POST request to the ngrok public URL\n",
        "public_url = ngrok_tunnel.public_url  # Use the URL from the previous cell\n",
        "response = requests.post(f\"{public_url}/predict\", json=student_input)\n",
        "print(\"Prediction:\", response.json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z6ao1EyqF_lZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}